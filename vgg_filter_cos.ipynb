{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg-filter-cos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1e_9HyoNEHF__OHd5f3YUeBh6UnQqJT4I",
      "authorship_tag": "ABX9TyN99i5iXduQHdD2aGLdD8gp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgdshkovi/Benn/blob/master/vgg_filter_cos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUh9Zj8KOgaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b14f68b-14a9-4d8f-d6e5-1cd14b69c810"
      },
      "source": [
        "%cd /content/drive/My Drive/Z/filter_pruning"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Z/filter_pruning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXiovxDcOqo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import math\n",
        "from sklearn.cluster import KMeans\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from models import *\n",
        "import spherical_kmeans as skm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzC-LtjJOql1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_batch_size = 256\n",
        "dataset = 'cifar10'\n",
        "cfg = [32, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 256, 256, 256, 'M', 256, 256, 256]\n",
        "filtered_cfg = [16, 32, 'M', 64, 64, 'M', 128, 128, 128, 'M', 128, 128, 128, 'M', 128, 128, 128]\n",
        "cuda = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSThDpoZOqit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load('L1_logs/model_best.pth.tar')\n",
        "checkpoint = torch.load('L1_logs/checkpoint.pth.tar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSOGFI1VOqg4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "033f3edc-1a5b-49d8-a15a-821afbe72ff7"
      },
      "source": [
        "model = vgg(dataset='cifar10', depth=16,cfg=cfg)\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPTesXsVOqfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model):\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if True else {}\n",
        "    if dataset == 'cifar10':\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            datasets.CIFAR10('./data.cifar10', train=False, transform=transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n",
        "            batch_size=test_batch_size, shuffle=True, **kwargs)\n",
        "    elif dataset == 'cifar100':\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            datasets.CIFAR100('./data.cifar100', train=False, transform=transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n",
        "            batch_size=test_batch_size, shuffle=True, **kwargs)\n",
        "    else:\n",
        "        raise ValueError(\"No valid dataset is given.\")\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    print('\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
        "        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
        "    return correct / float(len(test_loader.dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rFwdhr1Oqdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "def list_duplicates(seq):\n",
        "    tally = defaultdict(list)\n",
        "    for i,item in enumerate(seq):\n",
        "        tally[item].append(i)\n",
        "    return ((key,locs) for key,locs in tally.items() if len(locs)>1)\n",
        "\n",
        "\n",
        "def return_mask(wts, labels):\n",
        "\tmodsource = labels.copy()\n",
        "\t#print(wts)\n",
        "\tprint(labels)\n",
        "\tfor dup in sorted(list_duplicates(labels)):\n",
        "\t    print(dup)\n",
        "\t    lis = dup[1][1:]\n",
        "\t    a = torch.from_numpy(np.reshape(wts[dup[1][0]],(1,wts[dup[1][0]].size)))\n",
        "\t    #a = wts[dup[1][0]]\n",
        "\t    for i in lis:\n",
        "\t    \tb = torch.from_numpy(np.reshape(wts[i],(1,wts[i].size)))\n",
        "\t    \tprint(cos(a,b))\n",
        "\t    \tmodsource[i] = -1\n",
        "\n",
        "\tmask = []\n",
        "\tfor el in modsource:\n",
        "\t\tif el!=-1:\n",
        "\t\t\tmask.append(1)\n",
        "\t\telse:\n",
        "\t\t\tmask.append(0)\n",
        "\treturn mask\n",
        "\n",
        "\n",
        "def return_cluster_labels(feat_wts, no_of_clus):\n",
        "  res = skm.spherical_k_means(feat_wts,n_clusters=no_of_clus,random_state=10)\n",
        "  return res[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd1dEYfoOqZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "cb0bf1e8-5415-4b6c-90e7-ab6384be3294"
      },
      "source": [
        "cfg_mask = []\n",
        "layer_id = 0\n",
        "for m in model.modules():\n",
        "  if isinstance(m , nn.Conv2d):\n",
        "    shape = m.weight.data.shape\n",
        "    print(shape)\n",
        "    reshaped_tensor = m.weight.data.clone().numpy().reshape(shape[0] , shape[1]*shape[2]*shape[3])\n",
        "\n",
        "    labels = return_cluster_labels(reshaped_tensor,filtered_cfg[layer_id])\n",
        "    mask = return_mask(reshaped_tensor,labels)\n",
        "    cfg_mask.append(torch.tensor(mask))\n",
        "    layer_id += 1\n",
        "    break\n",
        "  elif isinstance(m, nn.MaxPool2d):\n",
        "    layer_id += 1"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 3, 3])\n",
            "[ 3  0  2  7  0  0 10  0 14 12 10  4 14  8 10 10  0  8  8  9  8  1 13  5\n",
            "  0 10 15 10  6 10 11  0]\n",
            "(0, [1, 4, 5, 7, 16, 24, 31])\n",
            "tensor([0.4126])\n",
            "tensor([0.7825])\n",
            "tensor([0.5401])\n",
            "tensor([0.7279])\n",
            "tensor([-0.0462])\n",
            "tensor([0.6637])\n",
            "(8, [13, 17, 18, 20])\n",
            "tensor([0.7631])\n",
            "tensor([0.7457])\n",
            "tensor([0.6151])\n",
            "(10, [6, 10, 14, 15, 25, 27, 29])\n",
            "tensor([0.0278])\n",
            "tensor([0.3798])\n",
            "tensor([0.5608])\n",
            "tensor([0.3032])\n",
            "tensor([0.1360])\n",
            "tensor([0.2130])\n",
            "(14, [8, 12])\n",
            "tensor([0.9121])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD4tz0ECR5aP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cos = nn.CosineSimilarity()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXNdDVlvRtOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.from_numpy(np.reshape(X[0],(1,X[0].size)))\n",
        "b = torch.from_numpy(np.reshape(X[5],(1,X[5].size)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YLbuGZ3OqWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newmodel = vgg(dataset = 'cifar10' ,cfg=filtered_cfg)\n",
        "newmodel.cuda()\n",
        "\n",
        "start_mask = torch.ones(3)\n",
        "layer_id_in_cfg = 0\n",
        "end_mask = cfg_mask[layer_id_in_cfg]\n",
        "for [m0, m1] in zip(model.modules(), newmodel.modules()):\n",
        "    if isinstance(m0, nn.BatchNorm2d):\n",
        "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
        "        if idx1.size == 1:\n",
        "            idx1 = np.resize(idx1,(1,))\n",
        "        m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n",
        "        m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n",
        "        m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n",
        "        m1.running_var = m0.running_var[idx1.tolist()].clone()\n",
        "        layer_id_in_cfg += 1\n",
        "        start_mask = end_mask\n",
        "        if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
        "            end_mask = cfg_mask[layer_id_in_cfg]\n",
        "    elif isinstance(m0, nn.Conv2d):\n",
        "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
        "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
        "        print('In shape: {:d}, Out shape {:d}.'.format(idx0.size, idx1.size))\n",
        "        if idx0.size == 1:\n",
        "            idx0 = np.resize(idx0, (1,))\n",
        "        if idx1.size == 1:\n",
        "            idx1 = np.resize(idx1, (1,))\n",
        "        w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
        "        w1 = w1[idx1.tolist(), :, :, :].clone()\n",
        "        m1.weight.data = w1.clone()\n",
        "    elif isinstance(m0, nn.Linear):\n",
        "        if layer_id_in_cfg == len(cfg_mask):\n",
        "            idx0 = np.squeeze(np.argwhere(np.asarray(cfg_mask[-1].cpu().numpy())))\n",
        "            if idx0.size == 1:\n",
        "                idx0 = np.resize(idx0, (1,))\n",
        "            m1.weight.data = m0.weight.data[:, idx0].clone()\n",
        "            m1.bias.data = m0.bias.data.clone()\n",
        "            layer_id_in_cfg += 1\n",
        "            continue\n",
        "        m1.weight.data = m0.weight.data.clone()\n",
        "        m1.bias.data = m0.bias.data.clone()\n",
        "    elif isinstance(m0, nn.BatchNorm1d):\n",
        "        m1.weight.data = m0.weight.data.clone()\n",
        "        m1.bias.data = m0.bias.data.clone()\n",
        "        m1.running_mean = m0.running_mean.clone()\n",
        "        m1.running_var = m0.running_var.clone()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTqxhffNOqSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save({'cfg': filtered_cfg, 'state_dict': newmodel.state_dict()},'Test_logs/pruned.pth.tar')\n",
        "print(newmodel)\n",
        "model = newmodel\n",
        "model.cuda()\n",
        "acc = test(model)\n",
        "\n",
        "num_parameters = sum([param.nelement() for param in newmodel.parameters()])\n",
        "with open( \"Test_logs/prune.txt\", \"w\") as fp:\n",
        "    fp.write(\"Number of parameters: \\n\"+str(num_parameters)+\"\\n\")\n",
        "    fp.write(\"Test accuracy: \\n\"+str(acc)+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDCzLOy_OqPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}